{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Creating kaggle ds from tfrecords -  imdb-sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwOYv0YrMD9L+L83VuUCDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kp425/nlp_lab/blob/master/Creating_kaggle_ds_from_tfrecords_imdb_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QGL6RKWE_zI",
        "outputId": "082d8aa3-6cf8-4abb-ec43-5a176bb7aae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/kp425/nlp_lab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp_lab'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 76 (delta 25), reused 41 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4KmP7FrwWKU",
        "outputId": "8bb2991d-63ea-4db0-ee44-15e13da94092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from nlp_lab.utils import WordTokenizer \n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cLtm4wOxq7F"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v40l8yTgxhcU",
        "outputId": "316b7bde-71e5-4db2-b82c-0ea804981ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 10s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2zbCdmIxuzM"
      },
      "source": [
        "def getfiles(folder):\n",
        "    files = glob.glob(f\"{folder}/*.txt\")\n",
        "    return files\n",
        "\n",
        "pos_path = '/content/aclImdb/train/pos'\n",
        "neg_path = '/content/aclImdb/train/neg'\n",
        "\n",
        "pos_files = getfiles(pos_path)\n",
        "neg_files = getfiles(neg_path)\n",
        "\n",
        "pos_ds = tf.data.TextLineDataset(pos_files,num_parallel_reads=AUTOTUNE)\n",
        "pos_ds = pos_ds.map(lambda x: (x,1.0), num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "neg_ds = tf.data.TextLineDataset(neg_files,num_parallel_reads=AUTOTUNE)\n",
        "neg_ds = neg_ds.map(lambda x: (x,0.0), num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "ds = pos_ds.concatenate(neg_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIhViyQtfZuy"
      },
      "source": [
        "pos_path = '/content/aclImdb/test/pos'\n",
        "neg_path = '/content/aclImdb/test/neg'\n",
        "\n",
        "pos_files = getfiles(pos_path)\n",
        "neg_files = getfiles(neg_path)\n",
        "\n",
        "pos_ds = tf.data.TextLineDataset(pos_files,num_parallel_reads=AUTOTUNE)\n",
        "pos_ds = pos_ds.map(lambda x: (x,1.0), num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "neg_ds = tf.data.TextLineDataset(neg_files,num_parallel_reads=AUTOTUNE)\n",
        "neg_ds = neg_ds.map(lambda x: (x,0.0), num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "test_ds = pos_ds.concatenate(neg_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG1_UYpTx-ME"
      },
      "source": [
        "max_tokens = None\n",
        "sequence_length = None\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "    return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                                                '')\n",
        "def vectorize_text(seq, label):\n",
        "    tmp_seq = tf.expand_dims(seq, -1)\n",
        "    enc_seq = vectorize_layer(tmp_seq)\n",
        "    seq_len = tf.shape(enc_seq)[-1]\n",
        "    return seq, seq_len, enc_seq, label\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "full_text = ds.map(lambda text, label: text)\n",
        "vectorize_layer.adapt(full_text)  #collects all vocabulary and assigns ID\n",
        "\n",
        "ds = ds.map(vectorize_text)\n",
        "test_ds = test_ds.map(vectorize_text)\n",
        "\n",
        "\n",
        "#pad the encoded_seqs \n",
        "\n",
        "pad_ds = ds.map(lambda x,y,z,w: tf.squeeze(z,axis=0))           #seperate encoded seqs\n",
        "pad_ds = pad_ds.padded_batch(25000)                        #pad the seqs\n",
        "pad_ds = pad_ds.unbatch()                                       #unbatch them again to individuals, padding persists\n",
        "pad_ds = pad_ds.cache()\n",
        "\n",
        "pad_test_ds = test_ds.map(lambda x,y,z,w: tf.squeeze(z,axis=0))   #seperate encoded seqs\n",
        "pad_test_ds = pad_test_ds.padded_batch(25000)                     #pad the seqs\n",
        "pad_test_ds = pad_test_ds.unbatch()                               #unbatch them again to individuals, padding persists\n",
        "pad_test_ds = pad_test_ds.cache()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JTmfbHJxNXM"
      },
      "source": [
        "#zip them with origianl datasets and remove unpadded sequences\n",
        "\n",
        "#removing unpadded_seqs \n",
        "_ds = ds.map(lambda *x: (x[0],x[1],x[3]))\n",
        "_test_ds = test_ds.map(lambda *x: (x[0],x[1],x[3]))\n",
        "\n",
        "# zip the og datasets with padded seqs\n",
        "_ds = tf.data.Dataset.zip((_ds, pad_ds))\n",
        "_test_ds = tf.data.Dataset.zip((_test_ds,pad_test_ds))\n",
        "\n",
        "#rearrange order\n",
        "_ds = _ds.map(lambda x, y: (x[0],x[1], y, x[2])).cache()\n",
        "_test_ds = _test_ds.map(lambda x, y: (x[0],x[1], y, x[2])).cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol9jv43PyC61"
      },
      "source": [
        "train_val_split = 0.9\n",
        "ds_size = 25000\n",
        "\n",
        "train_split = int(train_val_split * ds_size)\n",
        "val_split = ds_size - train_split \n",
        "\n",
        "_ds = _ds.shuffle(100000, seed = 101)\n",
        "train_ds = _ds.take(train_split)\n",
        "val_ds = _ds.skip(train_split).take(val_split)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIOv3cni-4WN",
        "outputId": "b4282bb9-d2ce-46b8-e385-507b499adf97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(sum([1 for i in train_ds]))\n",
        "print(sum([1 for i in val_ds]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22500\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU1lvK2Lq7lr",
        "outputId": "84cc4cc1-d672-42d3-c5b7-b387b3e91540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sum([1 for i in test_ds]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgybzNn2grAu",
        "outputId": "5af15283-271a-47a0-a223-794c1ac0be35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value = [value]))\n",
        "\n",
        "def _int_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value = [value]))\n",
        "\n",
        "\n",
        "def serialize_to_tfr(seq, seqlen, enc_seq, label):\n",
        "    def _serialize_seqs(seq, seqlen, enc_seq, label):\n",
        "        \n",
        "        seq = tf.io.serialize_tensor(seq)\n",
        "        enc_seq = tf.io.serialize_tensor(enc_seq)\n",
        "\n",
        "        feature = {\n",
        "             'seq': _bytes_feature(seq),\n",
        "             'seq_len': _int_feature(seqlen),\n",
        "             'enc_seq': _bytes_feature(enc_seq),\n",
        "             'label': _float_feature(label)}\n",
        "        \n",
        "\n",
        "        example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "        return example_proto.SerializeToString()\n",
        "    \n",
        "    tf_string = tf.py_function(_serialize_seqs ,\n",
        "                               (seq, seqlen, enc_seq, label), \n",
        "                               tf.string)      \n",
        "    return tf.reshape(tf_string, ()) \n",
        "\n",
        "\n",
        "\n",
        "train_ds = train_ds.map(lambda *x: serialize_to_tfr(x[0],x[1],x[2],x[3]))\n",
        "val_ds = val_ds.map(lambda *x: serialize_to_tfr(x[0],x[1],x[2],x[3]))\n",
        "test_ds = _test_ds.map(lambda *x: serialize_to_tfr(x[0],x[1],x[2],x[3]))\n",
        "\n",
        "\n",
        "\n",
        "folder = \"/content/imdb/\"\n",
        "os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "\n",
        "train_name = \"train.tfrecord\"\n",
        "val_name =   \"val.tfrecord\"\n",
        "test_name =  \"test.tfrecord\"\n",
        "\n",
        "print('1')\n",
        "writer = tf.data.experimental.TFRecordWriter(os.path.join(folder, train_name))\n",
        "writer.write(train_ds)\n",
        "\n",
        "print('2')\n",
        "writer = tf.data.experimental.TFRecordWriter(os.path.join(folder, val_name))\n",
        "writer.write(val_ds)\n",
        "\n",
        "print('3')\n",
        "writer = tf.data.experimental.TFRecordWriter(os.path.join(folder, test_name))\n",
        "writer.write(test_ds)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or9pHXGgEToX"
      },
      "source": [
        "import json\n",
        "\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "tokens = {u:i for i,u in enumerate(vocab)}\n",
        "\n",
        "with open(folder + 'tokens.json', 'w') as fp:\n",
        "    json.dump(tokens, fp)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdEaaP7Ul3He",
        "outputId": "f6957a80-6c4e-4cdb-979e-796a164733b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def parse_from_tfr(element):\n",
        "\n",
        "    feature_description = \\\n",
        "        {'seq': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "        'seq_len': tf.io.FixedLenFeature([], tf.int64, default_value= 0),\n",
        "        'enc_seq': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
        "        'label': tf.io.FixedLenFeature([], tf.float32, default_value=0.0)}\n",
        "\n",
        "    output = tf.io.parse_example(element, feature_description)\n",
        "    seq = tf.io.parse_tensor(output['seq'], out_type = tf.string)\n",
        "    seq_len = output['seq_len']\n",
        "    enc_seq = tf.io.parse_tensor(output['enc_seq'], out_type = tf.int64)\n",
        "    enc_seq = tf.cast(enc_seq, tf.int32)\n",
        "    label = output['label']\n",
        "\n",
        "    return seq, seq_len, enc_seq, label\n",
        "\n",
        "\n",
        "te = tf.data.TFRecordDataset(['/content/imdb/test.tfrecord'])\n",
        "te = te.map(parse_from_tfr)\n",
        "print(sum([1 for i in te]))\n",
        "\n",
        "\n",
        "tr = tf.data.TFRecordDataset(['/content/imdb/train.tfrecord'])\n",
        "tr = tr.map(parse_from_tfr)\n",
        "print(sum([1 for i in tr]))\n",
        "\n",
        "v = tf.data.TFRecordDataset(['/content/imdb/val.tfrecord'])\n",
        "v = v.map(parse_from_tfr)\n",
        "print(sum([1 for i in v]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "22500\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA8kt5Wlu_iu",
        "outputId": "8b177e6e-3ef7-4744-8dcb-172b833c93ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "for i in te.take(1):\n",
        "    print(i[0])\n",
        "    print(i[1])\n",
        "    print(i[2])\n",
        "    print(i[3])\n",
        "print(\"\\n\")\n",
        "for i in tr.take(2):\n",
        "    print(i[0])\n",
        "    print(i[1])\n",
        "    print(i[2])\n",
        "    print(i[3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'Late one night on Tom Snyder\\'s \"Tomorrow\" Show, I watched Tom ask his guest Henry Morgan what he considered to be \\'perfect.\\' Morgan responded, \"Anything with Glenda Jackson.\" And although I wouldn\\'t consider this film to be perfect, it does bear out that notion very well. I was about to use the clich\\xc3\\xa9\\' about Hollywood not making pictures like this anymore, but then I just saw, \"Up in the Air,\" another intelligent film about 2 people over the age of 35 who fall in love. That\\'s where the similarities end, though. \"House Calls\" is just sheer fun watching 2 pros like Matthau and Jackson hit it off and seem completely natural while they\\'re at it. I saw this film in the theater in 1978 (at the ripe old age of 18) and it took me another 20 years to get all of the jokes. Any film that can make punch lines out of 1920\\'s tennis great Bill Tilden, and British Prime Minister Neville Chamberlain wouldn\\'t play too well at the megaplex these days. One other thought: the original theatrical release featured a \\'walk on the beach / fall in love\\' montage set to The Beatles/George Harrison tune, \"Something.\" It seemed a bit forced at the time, but that song has since been swapped out for a rather generic Henry Mancini music cue for subsequent home video and cable release. Too bad, because that scene just lays there now, another victim of music licensing Hell.', shape=(), dtype=string)\n",
            "tf.Tensor(243, shape=(), dtype=int64)\n",
            "tf.Tensor([528  28 310 ...   0   0   0], shape=(2226,), dtype=int32)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "\n",
            "\n",
            "tf.Tensor(b'It is wonderful to watch Roshan Seth (the strict father in 1992 \"Mississippi Masala\"), who once again takes on the role of a father and head of the family, and more, in SUCH A LONG JOURNEY, set in 1971 Bombay, India. Besides the closely knit family settings, subject matters include the lost and found of a friendship; the unexpected death of a friend (somehow the calm smiling face of a friend in death in the presence of prayers felt peaceful - so Gustad Noble, Roshan\\'s character, similarly noted); a sidewalk artist\\'s chain of events - \"the wall as a latrine turned into a shrine\\xc2\\x85shrine into rumbles and ashes\" was at once prophetic and philosophical. It\\'s packed full of life lessons in different aspects of varying relationships: between father and son; mother and son; father and little daughter; little daughter and father and mother; longtime colleagues; long lost dear friends; even that of a man to man, one whose an innocent slow-witted \"fool\".<br /><br />In spite of the tone of the film\\'s era, it\\'s a colorful film rich in substance, and the strength of the story in textural layers with humor and suspense. For a director who is not Indian (Sturla Gunnarsson being Icelandic), he\\'s made a political Indian/Pakistani film. He gets into the bone marrow of the life of this Parsi portrayed by Roshan Seth, whose performance has such nuances, subtlety, and joy. (There is singing, too.) The rest of the cast is equally strong: from Om Puri the mysterious friend of a friend; Soni Razdan the enduring wife; Vrajesh Hirjee the argumentative eldest son; Sam Dastor the longtime office mate; Ranjit Chowdhry the pavement artist; to a superstitious \"witch\" woman of a neighbor; an unbeguiling \"fool\" of a man; and a long lost bosom friend - it\\'s a world of many faces and perspectives. Director Gunnarsson has demonstrated sensitivity in the treatment of that time period and subject was well researched with attention to details. He has the good fortune to have Sooni Taraporevala (1992 \"Mississippi Masala\", 1988 \"Salaam Bombay!\") wrote the script. This is truly a worthwhile journey of a film to partake.<br /><br />Along the lines of cultural exploration (road movie style), Fridrik Thor Fridriksson 1994 \"Cold Fever\" is an Icelandic sojourn about a Japanese young man who went across the globe in search of the specific spot to pay his last respects to his parents, dutifully following memorial rituals for the dead. Such demonstrated reverence and cross-cultural attention to family ties are heart-warming in this day and cyber age.', shape=(), dtype=string)\n",
            "tf.Tensor(418, shape=(), dtype=int64)\n",
            "tf.Tensor([  9   7 373 ...   0   0   0], shape=(2459,), dtype=int32)\n",
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(b'The Marquis De Sade, Egypt, ancient Gnostic cults, Robert Englund in a dual role, gratuitous sex and nudity, murder and mayhem... on paper Tobe Hopper\\'s Night Terrors sounds like it should be at least a fun, entertaining flick given the ingredients. It\\'s not. It is a plot less, incoherent shambles that brings little entertainment. There is basically no plot beyond some vague stuff about a cult that follows the work of De Sade who for some unclear reason feel the need to seduce the daughter of a local Christian archaeologist and kill her. That is pretty much it- I think it has something to with the Gnostics but who knows what the writers were thinking. Most of the movie is a meandering mess as the heroine is exposed to various weirdness, dream sequences and erotic encounters, intercut with scenes of Englund as the imprisoned De Sade in the 19th century chewing the scenery. It seems like the makers were trying for something serious but whatever their pretensions were they are buried in the cheesiness, bad acting, sleaze and fake looking decapitated heads.<br /><br />There aren\\'t too many good points. Robert Englund is fun to watch, as always and the lead actress, Zoe Trilling, whilst not very talented, is attractive and in various stages of undress through the movie but watching Night Terrors is a chore. At least I got to see the movie from which the \"When you\\'re as criminal as I\" bit from the Australian film certification ratings guide that was on the front of so many VHS tapes from the nineties came from.', shape=(), dtype=string)\n",
            "tf.Tensor(264, shape=(), dtype=int64)\n",
            "tf.Tensor([   2 9642  849 ...    0    0    0], shape=(2459,), dtype=int32)\n",
            "tf.Tensor(0.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCfJjxWgK6uX",
        "outputId": "6a9efabd-c80f-4a6f-d508-31aaa04e1c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "id2vocab = {v:k for k,v in tokens.items()}\n",
        "\n",
        "sen = []\n",
        "\n",
        "for i in t.skip(12499).take(1):\n",
        "    print(i[0])\n",
        "    for j in i[2].numpy():\n",
        "        sen.append(id2vocab[j])\n",
        "\n",
        "print(' '.join(sen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"I thought this movie was fun. I have never really watched old movies before and this one was a really great first date film. It had warmth and heart and spirit. Was kind of cheesy but in today's film industry, cheesy is cute. I gave it a ten and I highly suggest renting, buying or seeing the movie anyway you can. Gene Kelly was very dreamy and a little bit sarcastic and you knew the character thought that he was gonna have it all. The female lead was cast perfect because their two personalities had spark and you wanted to hold on and see what would happen. The grandma in the movie was priceless. The perfect addition to a great old movie. I love the fact it was black and white and Gene Kelly is so sweet with all the kids in the movie that you can't help liking him. See It.\", shape=(), dtype=string)\n",
            "i thought this movie was fun i have never really watched old movies before and this one was a really great first date film it had warmth and heart and spirit was kind of cheesy but in todays film industry cheesy is cute i gave it a ten and i highly suggest renting buying or seeing the movie anyway you can gene kelly was very dreamy and a little bit sarcastic and you knew the character thought that he was gonna have it all the female lead was cast perfect because their two personalities had spark and you wanted to hold on and see what would happen the grandma in the movie was priceless the perfect addition to a great old movie i love the fact it was black and white and gene kelly is so sweet with all the kids in the movie that you cant help liking him see it                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW_6NuBrRLUf"
      },
      "source": [
        "# Now create Kaggle ds from tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWW-v0AkRQOq",
        "outputId": "6085891a-0f59-4813-bd9d-78311f52e946",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c803973-3933-49ca-8687-4da163f9aff5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c803973-3933-49ca-8687-4da163f9aff5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JRX0ve0UaxU",
        "outputId": "38cfc8fa-484c-4d99-9f7b-462ecaa746d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd /content/imdb\n",
        "! kaggle datasets init"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/imdb\n",
            "Data package template written to: /content/imdb/dataset-metadata.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebIOoIimSGA3",
        "outputId": "77dd4a9d-e673-4c76-d221-d718f4f16b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "! kaggle datasets create -p /content/imdb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting upload for file val.tfrecord\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "100% 50.3M/50.3M [00:09<00:00, 5.44MB/s]\n",
            "Upload successful: val.tfrecord (50MB)\n",
            "Starting upload for file test.tfrecord\n",
            "100% 458M/458M [00:29<00:00, 16.3MB/s]\n",
            "Upload successful: test.tfrecord (458MB)\n",
            "Starting upload for file tokens.json\n",
            "100% 2.10M/2.10M [00:08<00:00, 254kB/s]\n",
            "Upload successful: tokens.json (2MB)\n",
            "Starting upload for file train.tfrecord\n",
            "100% 453M/453M [00:29<00:00, 16.2MB/s]\n",
            "Upload successful: train.tfrecord (453MB)\n",
            "Your private Dataset is being created. Please check progress at https://www.kaggle.com/loveyoutoo/imdbsentiment\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}