{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU optimized custom training loops.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmaBoPYIGmiHUYT9cEjfGs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kp425/nlp_lab/blob/master/TPU_optimized_custom_training_loops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yd6xOF2TMZ9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Sequential\n",
        "import random\n",
        "\n",
        "tf.random.set_seed(101)\n",
        "random.seed(101)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1cwQcFfTWy5"
      },
      "source": [
        "def connect_to_tpu():\n",
        "\n",
        "    try: # detect TPUs\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "        print(\"Running on TPU  \", resolver.master())\n",
        "    except ValueError: # detect GPUs\n",
        "        resolver = None\n",
        "\n",
        "    if resolver:\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "        strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "    else:\n",
        "        strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "        #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "        #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "    \n",
        "    return strategy\n",
        "\n",
        "\n",
        "strategy = connect_to_tpu()\n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZiVfHQSyHCX"
      },
      "source": [
        "# Sample Input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfH_QP4HTadG"
      },
      "source": [
        "w = 16\n",
        "h = 16\n",
        "c = 3\n",
        "n_classes = 10\n",
        "sample_size = 1280\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "images = tf.random.normal((sample_size, w, h, c), 2.0,0.01)\n",
        "labels = [random.randint(0,n_classes-1) for _ in range(sample_size)]\n",
        "labels = tf.convert_to_tensor(labels, dtype = tf.float32)\n",
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices((images, labels)).cache().batch(BATCH_SIZE)\n",
        "dist_ds = strategy.experimental_distribute_dataset(ds)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpocs5sJyW97"
      },
      "source": [
        "Create Identical models for each `train_step`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKTxDZ3Zu8QK"
      },
      "source": [
        "tf.random.set_seed(101)\n",
        "random.seed(101)\n",
        "\n",
        "\n",
        "def make_model():\n",
        "    return Sequential([layers.Flatten(),\n",
        "                        layers.Dense(32, activation = 'relu'),\n",
        "                        layers.Dense(n_classes)])\n",
        "\n",
        "\n",
        "\n",
        "reference_model = make_model()\n",
        "#initialize weights, so they can be copied to model in strategy scope\n",
        "reference_model(next(iter(ds))[0])\n",
        "\n",
        "model = None\n",
        "model_weights = reference_model.get_weights()\n",
        "train_loss = None\n",
        "train_acc = None\n",
        "test_loss = None\n",
        "test_acc = None\n",
        "optimizer = None\n",
        "loss_object = None\n",
        "loss_function = None\n",
        "forward_pass = None\n",
        "\n",
        "def refresh(apply_strategy=True):\n",
        "\n",
        "    def _refresh():\n",
        "        global model, model_weights, train_loss, train_acc, \\\n",
        "                test_loss, test_acc, optimizer, loss_object, \\\n",
        "                loss_function, forward_pass\n",
        "\n",
        "        \n",
        "        model = make_model()\n",
        "        model.build((None, w,h,c))\n",
        "        model.set_weights(model_weights)\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "        train_acc = tf.keras.metrics.SparseCategoricalAccuracy('training_acc', dtype=tf.float32)\n",
        "\n",
        "        test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
        "        test_acc = tf.keras.metrics.SparseCategoricalAccuracy('test_acc', dtype=tf.float32)\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "    \n",
        "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                    from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "        def loss_function(labels, preds):\n",
        "            per_example_loss = loss_object(labels, preds)\n",
        "            return tf.nn.compute_average_loss(per_example_loss, global_batch_size= BATCH_SIZE)\n",
        "\n",
        "        def forward_pass(ds_chunk):\n",
        "            inputs, labels = ds_chunk\n",
        "            preds = model(inputs)\n",
        "            return preds, labels\n",
        "    \n",
        "    if apply_strategy:\n",
        "        with strategy.scope():\n",
        "            _refresh()\n",
        "    else:\n",
        "        _refresh()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgcXHphuV0cU"
      },
      "source": [
        "# Different types of custom strategy loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKTvApfLxoRP"
      },
      "source": [
        "Always use `multi_train_steps` or `train_epochs`, since they use 80-90% MXU and 0% idle time on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1wd_k3jHDYo"
      },
      "source": [
        "@tf.function\n",
        "def simple_train_step(ds_chunk):\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        preds, labels = forward_pass(ds_chunk)\n",
        "        loss_val = loss_object(labels, preds)\n",
        "    gradients = tape.gradient(loss_val, model.trainable_variables) \n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n",
        "                                 experimental_aggregate_gradients=True)\n",
        "    train_loss.update_state(loss_val)\n",
        "    train_acc.update_state(labels, preds)\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def dist_train_step_v1(ds_chunk):\n",
        "    def _train_step(ds_chunk):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            preds, labels = forward_pass(ds_chunk)\n",
        "            loss_val = loss_function(labels, preds)\n",
        "        gradients = tape.gradient(loss_val, model.trainable_variables) \n",
        "        \n",
        "        '''custom gradient aggregation can be done by using replica_context\n",
        "            \n",
        "            grads = tape.gradient(loss, vars)\n",
        "            grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n",
        "            # Processing aggregated gradients.\n",
        "            optimizer.apply_gradients(zip(grads, vars),\n",
        "                                experimental_aggregate_gradients=False)\n",
        "        '''\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n",
        "                                     experimental_aggregate_gradients=True)\n",
        "        return loss_val, preds, labels\n",
        "\n",
        "    #computations run on each replica parallely\n",
        "    per_replica_losses, preds, labels = strategy.run(_train_step, args = (ds_chunk,))\n",
        "    # strategy implicitly agrregate loss_vals and gradients by itself....\n",
        "    # the reason we execute the below line is only to record the value in metrics\n",
        "    global_batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "    preds = tf.concat(preds.values, axis = 0)\n",
        "    labels = tf.concat(labels.values, axis = 0)\n",
        "    train_loss.update_state(global_batch_loss)\n",
        "    train_acc.update_state(labels, preds)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def dist_train_step_v2(ds_chunk):\n",
        "    def _train_step(ds_chunk):\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds, labels = forward_pass(ds_chunk)\n",
        "            loss_val = loss_function(labels, preds)\n",
        "\n",
        "        # tf.debugging.assert_shapes([(preds, (BATCH_SIZE//strategy.num_replicas_in_sync, n_classes))])\n",
        "        # tf.debugging.assert_shapes([(labels, (BATCH_SIZE//strategy.num_replicas_in_sync,))])\n",
        "        \n",
        "        gradients = tape.gradient(loss_val, model.trainable_variables) \n",
        "   \n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n",
        "                                     experimental_aggregate_gradients=True)\n",
        "        \n",
        "        ''' Here the loss_val is the loss value of a single replica. \n",
        "            Since the metric we are using here is Mean, \n",
        "            the loss_val at the end of the batched is scaled-down to 1/(num_of_replicas),\n",
        "            To negate this effect, we multiply each loss_val with num_of_replicas, \n",
        "            so when the mean is taken, we will real loss_val (like total_loss_per_batch/ batch_size)\n",
        "\n",
        "            To avoid this complexity, we can simply use Sum metric\n",
        "            eg:\n",
        "             train_loss = tf.keras.metrics.Sum()\n",
        "             train_loss.update_state(loss_val)\n",
        "\n",
        "             https://www.tensorflow.org/tutorials/distribute/custom_training#tracking_training_loss_across_replicas\n",
        "             https://www.tensorflow.org/guide/tpu#input_datasets\n",
        "        '''\n",
        "        train_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n",
        "        train_acc.update_state(labels, preds)\n",
        "\n",
        "    strategy.run(_train_step, args = (ds_chunk,))\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def multiple_dist_train_steps_v1(dist_iter, steps):\n",
        "    def _train_step(ds_chunk):\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds, labels = forward_pass(ds_chunk)\n",
        "            loss_val = loss_function(labels, preds)\n",
        "        \n",
        "        gradients = tape.gradient(loss_val, model.trainable_variables) \n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n",
        "                                 experimental_aggregate_gradients=True)\n",
        "        return loss_val, preds, labels\n",
        "    \n",
        "    for _ in tf.range(steps):\n",
        "        optional_data = dist_iter.get_next_as_optional()\n",
        "        if not optional_data.has_value():\n",
        "            break\n",
        "        per_replica_losses, preds, labels = strategy.run(_train_step, args=(optional_data.get_value(),))\n",
        "        global_batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "        labels = tf.concat(labels.values, axis = 0)\n",
        "        preds = tf.concat(preds.values, axis = 0)\n",
        "        train_loss.update_state(global_batch_loss)\n",
        "        train_acc.update_state(labels, preds)  \n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def multiple_dist_train_steps_v2(dist_iter, steps):\n",
        "    \n",
        "    def _train_step(ds_chunk):\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds, labels = forward_pass(ds_chunk)\n",
        "            loss_val = loss_function(labels, preds)\n",
        "        tf.debugging.assert_shapes([(preds, (BATCH_SIZE, 10))])\n",
        "        # tf.debugging.assert_shapes([(labels, (142,))])\n",
        "        gradients = tape.gradient(loss_val, model.trainable_variables) \n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n",
        "                                     experimental_aggregate_gradients=True)\n",
        "        \n",
        "        train_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n",
        "        train_acc.update_state(labels, preds)\n",
        "    \n",
        "    for _ in tf.range(steps):\n",
        "        optional_data = dist_iter.get_next_as_optional()\n",
        "        if not optional_data.has_value():\n",
        "            break\n",
        "        strategy.run(_train_step, args=(optional_data.get_value(),))\n",
        "        # tf.print(strategy.experimental_local_results(per_replica_results))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def dist_train_epoch(ds):\n",
        "     #https://www.tensorflow.org/tutorials/distribute/custom_training#iterating_inside_a_tffunction\n",
        "    def _train_step(ds_chunk):\n",
        "        with tf.GradientTape() as tape:\n",
        "            preds, labels = forward_pass(ds_chunk)\n",
        "            loss_val = loss_function(labels, preds)\n",
        "        gradients = tape.gradient(loss_val, model.trainable_variables) \n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables),\n",
        "                                 experimental_aggregate_gradients=True)\n",
        "      \n",
        "        train_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n",
        "        train_acc.update_state(labels, preds)\n",
        "    for chunk in ds:\n",
        "        strategy.run(_train_step, args = (chunk,))\n",
        "\n",
        "\n",
        "steps_per_epoch = sum([1 for _ in dist_ds])\n",
        "steps = 3\n",
        "epochs = 1\n",
        "\n",
        "refresh(apply_strategy=False)\n",
        "for i,chunk in enumerate(ds):\n",
        "    if i==steps:break\n",
        "    simple_train_step(chunk)\n",
        "print(f\"loss :{train_loss.result()}  acc:{train_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "for i,chunk in enumerate(dist_ds):\n",
        "    if i==steps:break\n",
        "    dist_train_step_v1(chunk)\n",
        "print(f\"loss :{train_loss.result()}  acc:{train_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "for i,chunk in enumerate(dist_ds):\n",
        "    if i==steps:break\n",
        "    dist_train_step_v2(chunk)\n",
        "print(f\"loss :{train_loss.result()}  acc:{train_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "multiple_dist_train_steps_v1(iter(dist_ds),steps)\n",
        "print(f\"loss :{train_loss.result()}  acc:{train_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "multiple_dist_train_steps_v2(iter(dist_ds),steps)\n",
        "print(f\"loss :{train_loss.result()}  acc:{train_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "for epoch in range(epochs):\n",
        "    dist_train_epoch(dist_ds)\n",
        "print(f\"loss :{train_loss.result()}  acc:{train_acc.result()}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH53Pa0mr-Qq"
      },
      "source": [
        "# Test steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulbeCCCZIWUW",
        "outputId": "1040fba5-8107-46b4-e1fd-dc28c8b98b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "@tf.function\n",
        "def simple_test_step(ds_chunk):\n",
        "    preds, labels = forward_pass(ds_chunk)\n",
        "    loss_val = loss_object(labels, preds)\n",
        "    test_loss.update_state(loss_val)\n",
        "    test_acc.update_state(labels, preds)\n",
        "    return loss_val, test_acc.result()\n",
        "\n",
        "@tf.function\n",
        "def dist_test_step_v1(ds_chunk):\n",
        "    def _test_step(ds_chunk):\n",
        "        preds, labels = forward_pass(ds_chunk)\n",
        "        loss_val = loss_function(labels, preds)\n",
        "        return loss_val, preds, labels\n",
        "    per_replica_losses, preds, labels = strategy.run(_test_step, args=(ds_chunk,))\n",
        "    global_batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "    labels = tf.concat(labels.values, axis = 0)\n",
        "    preds = tf.concat(preds.values, axis = 0)\n",
        "    test_loss.update_state(global_batch_loss)\n",
        "    test_acc.update_state(labels, preds)\n",
        "    return labels\n",
        "\n",
        "@tf.function\n",
        "def dist_test_step_v2(ds_chunk):\n",
        "    def _test_step(ds_chunk):\n",
        "        preds, labels = forward_pass(ds_chunk)\n",
        "        loss_val = loss_function(labels, preds)\n",
        "        test_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n",
        "        test_acc.update_state(labels, preds)\n",
        "    strategy.run(_test_step, args=(ds_chunk,))\n",
        "\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def multiple_dist_test_steps_v1(dist_iter, steps):\n",
        "    def _test_step(ds_chunk):\n",
        "        preds, labels = forward_pass(ds_chunk)\n",
        "        loss_val = loss_function(labels, preds)\n",
        "        return loss_val, preds, labels\n",
        "    \n",
        "    for _ in tf.range(steps):\n",
        "        optional_data = dist_iter.get_next_as_optional()\n",
        "        if not optional_data.has_value():\n",
        "            break\n",
        "        per_replica_losses, preds, labels = strategy.run(_test_step, args=(optional_data.get_value(),))\n",
        "        global_batch_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "        labels = tf.concat(labels.values, axis = 0)\n",
        "        preds = tf.concat(preds.values, axis = 0)\n",
        "        test_loss.update_state(global_batch_loss)\n",
        "        test_acc.update_state(labels, preds)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def multiple_dist_test_steps_v2(dist_iter, steps):\n",
        "    def _test_step(ds_chunk):\n",
        "        preds, labels = forward_pass(ds_chunk)\n",
        "        loss_val = loss_function(labels, preds)\n",
        "        test_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n",
        "        test_acc.update_state(labels, preds)\n",
        "\n",
        "    for _ in tf.range(steps):\n",
        "        optional_data = dist_iter.get_next_as_optional()\n",
        "        if not optional_data.has_value():\n",
        "            break\n",
        "        strategy.run(_test_step, args=(optional_data.get_value(),))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def dist_test_epoch(ds):\n",
        "     #https://www.tensorflow.org/tutorials/distribute/custom_training#iterating_inside_a_tffunction\n",
        "    def _test_step(ds_chunk):   \n",
        "        preds, labels = forward_pass(ds_chunk)\n",
        "        loss_val = loss_function(labels, preds)\n",
        "        test_loss.update_state(loss_val * strategy.num_replicas_in_sync)\n",
        "        test_acc.update_state(labels, preds)\n",
        "\n",
        "    for chunk in ds:\n",
        "        strategy.run(_test_step, args = (chunk,))\n",
        "\n",
        "\n",
        "\n",
        "steps_per_epoch = sum([1 for _ in dist_ds])\n",
        "epochs = 1\n",
        "steps = steps_per_epoch\n",
        "\n",
        "full = ds.unbatch().batch(2000)\n",
        "chunk = next(iter(full))\n",
        "refresh(apply_strategy=False)\n",
        "simple_test_step(chunk)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")\n",
        "\n",
        "\n",
        "refresh(apply_strategy=False)\n",
        "for i,chunk in enumerate(ds):\n",
        "    if i==steps:break\n",
        "    simple_test_step(chunk)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "for i,chunk in enumerate(dist_ds):\n",
        "    if i==steps:break\n",
        "    dist_test_step_v1(chunk)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "for i,chunk in enumerate(dist_ds):\n",
        "    if i==steps:break\n",
        "    dist_test_step_v2(chunk)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")\n",
        "\n",
        "\n",
        "refresh()\n",
        "multiple_dist_test_steps_v1(iter(dist_ds), steps)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")\n",
        "\n",
        "refresh()\n",
        "multiple_dist_test_steps_v2(iter(dist_ds), steps)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")\n",
        "\n",
        "\n",
        "refresh()\n",
        "dist_test_epoch(dist_ds)\n",
        "print(f\"loss :{test_loss.result()}  acc:{test_acc.result()}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss :3.4065730571746826  acc:0.10234375298023224\n",
            "loss :3.4065730571746826  acc:0.10234375298023224\n",
            "loss :3.4080862998962402  acc:0.10234375298023224\n",
            "loss :3.4080862998962402  acc:0.10234375298023224\n",
            "loss :3.4080862998962402  acc:0.10234375298023224\n",
            "loss :3.4080862998962402  acc:0.10234375298023224\n",
            "loss :3.4080862998962402  acc:0.10234375298023224\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}